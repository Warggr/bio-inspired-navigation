rule:
	output: "data/trajectories/trajectories.hd5"
	shell:
		"python data_generation/gen_trajectories.py --extension '.hd5.part' && "
		"ln -s $(basename {output}).part {output}"

rule:
	output: "data/trajectories/{map}.trajectories.hd5"
	shell:
		"python data_generation/gen_trajectories.py --env-model {wildcards.map} --extension '.hd5.part' && "
		"ln -s $(basename {output}).part {output}"

rule:
	input: "data/trajectories/trajectories.hd5"
	output: "data/reachability/trajectories.hd5"
	shell: "ln -sf ../trajectories/trajectories.hd5 {output}"

rule:
	input: "data/trajectories/{map}.trajectories.hd5"
	output: "data/reachability/{map}.trajectories.hd5"
	shell: "ln -sf ../trajectories/{map}.trajectories.hd5 {output}"

rule:
    output: f"data/reachability/dataset.hd5"
    input: "data/reachability/trajectories.hd5"
    shell:
        f"python data_generation/dataset.py -n 200000 --flush-freq 1000 --extension '.hd5.part' && "
        "ln -s $(basename {output}).part {output}"
rule:
    output: "data/reachability/dataset-map{map}.hd5"
    input: "data/reachability/{map}.trajectories.hd5"
    shell:
        "python data_generation/dataset.py {output}.part {input} -n 200000 --flush-freq 1000 --extension '.hd5.part' && "
        "ln -s $(basename {output}).part {output}"

for wall_colors in ('3colors', 'patterns'):
    rule:
        input: "data/reachability/{basename}.hd5"
        output: f"data/reachability/{{basename}}-{wall_colors}.hd5"
        shell: f"python data_generation/clone_dataset.py {{input}} {{output}} -n 'all' --wall-colors {wall_colors}"

def dataset_for(wildcards):
    if wildcards.flags.startswith('-3colors'):
        return 'data/reachability/dataset-3colors.hd5'
    elif wildcards.flags.startswith('-patterns'):
        return 'data/reachability/dataset-patterns.hd5'
    else:
        return 'data/reachability/dataset.hd5'

rule:
    output: "data/models/reachability_network{flags}.25"
    input: dataset_for
    shell: """
        flags=$(python scripts/network_name.py cmdline {wildcards.model})
		python training/train_multiframe_dst.py train $flags --resume
    """

rule:
	output: "data/models/reachability_network{flags}+pretrained.25"
	input: dataset_for, "data/models/autoencoder20.25"
	shell: """
		flags=$(python scripts/network_name.py cmdline {wildcards.model})
		python training/train_multiframe_dst.py train $flags --resume
	"""

rule:
	input: "data/models/{model}"
	output: "logs/SimulationRExNetworkRE({model}).log"
	shell: """
		python data_generation/crosscheck.py simulation 'neural_network({wildcards.model})' binary > '{output}'
	"""

models = ['reachability_network+noimages+conv.25', 'reachability_network+spikings+lidar--raw_lidar.25', 'reachability_network-3colors+lidar--ego_bc.25']

rule:
	input: ["data/models/" + model for model in models]
	output: "logs/SimulationRExCombine(" + ",".join(map(lambda filename: f"Network({filename})", models)) + ").log"
	shell: f"""
		python data_generation/crosscheck.py simulation 'combine:{'x'.join(map(lambda filename: 'neural_network(' + filename + ')', models))}' binary > '{{output}}'
	"""

rule:
	output: f"data/results/{{model}}-val{{tag}}.log"
	input: f"data/models/{{model}}", "data/reachability/dataset{tag}.hd5"
	shell: """
		flags=$(python scripts/network_name.py cmdline {wildcards.model})
		# we need the eval because of some shell quoting issue
		eval python training/train_multiframe_dst.py validate --load {input} --dataset-basename "dataset{wildcards.tag}" $flags > {output}
	"""

code_sizes = [0, 1, 4, 16, 20, 50, 80, 100]
AUTOENCODER_EPOCHS = 25

rule:
	output: f"data/models/autoencoder{{i}}.{AUTOENCODER_EPOCHS}"
	input: 'data/reachability/dataset.hd5'
	shell: f'python training/train_autoencoder.py train {{wildcards.i}} -e {AUTOENCODER_EPOCHS}'

rule:
	output: f"data/results/autoencoder{{i}}.${AUTOENCODER_EPOCHS}.log"
	input: f"data/models/autoencoder{{i}}.{AUTOENCODER_EPOCHS}"
	shell: 'python training/train_autoencoder.py validate {wildcards.i} > {output}'

rule:
	input: [f"data/results/autoencoder{i}.25.log" for i in code_sizes]
	output: "data/results/autoencoder_performance.csv"
	run:
		with open(str(output), 'w') as outfile:
			print('Dimension of the encoding','MSE loss', sep=',', file=outfile)
			for i in code_sizes:
				with open(f'data/results/autoencoder{code_size}.{AUTOENCODER_EPOCHS}.log') as result_file:
					value = result_file.read().strip()
				value = value.split(' ')[1]
				print(i, value, sep=',', file=outfile)


for format in ('png', 'pgf'):
	rule:
		input: "data/results/autoencoder_performance.csv"
		output: f"data/results/autoencoder_performance.{format}"
		run:
			import matplotlib
			matplotlib.use("Agg")
			import matplotlib.pyplot as plt
			import pandas as pd

			data = pd.read_csv(str(input))
			x, y = data.keys()
			plt.scatter(data[x], data[y])
			plt.title("Autoencoder performance")
			plt.xlabel(x); plt.ylabel(y)
			plt.savefig(str(output))
